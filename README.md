# üéµ AMT (Audio Music Transformer)

AMT l√† m·ªôt h·ªá th·ªëng t·∫°o nh·∫°c t·ª± ƒë·ªông d·ª±a tr√™n m√¥ t·∫£ vƒÉn b·∫£n, s·ª≠ d·ª•ng ki·∫øn tr√∫c Transformer k·∫øt h·ª£p BERT v√† GPT-2 ƒë·ªÉ t·∫°o ra √¢m nh·∫°c t·ª´ m√¥ t·∫£ vƒÉn b·∫£n.

## üìã M·ª•c l·ª•c
- [T·ªïng quan](#t·ªïng-quan)
- [Ki·∫øn tr√∫c h·ªá th·ªëng](#ki·∫øn-tr√∫c-h·ªá-th·ªëng)
- [C√¥ng ngh·ªá s·ª≠ d·ª•ng](#c√¥ng-ngh·ªá-s·ª≠-d·ª•ng)
- [C√†i ƒë·∫∑t](#c√†i-ƒë·∫∑t)
- [S·ª≠ d·ª•ng](#s·ª≠-d·ª•ng)
- [Pipeline x·ª≠ l√Ω d·ªØ li·ªáu](#pipeline-x·ª≠-l√Ω-d·ªØ-li·ªáu)
- [Model Architecture](#model-architecture)
- [ƒê√°nh gi√°](#ƒë√°nh-gi√°)
- [K·∫øt qu·∫£](#k·∫øt-qu·∫£)
- [H∆∞·ªõng ph√°t tri·ªÉn](#h∆∞·ªõng-ph√°t-tri·ªÉn)
- [ƒê√≥ng g√≥p](#ƒë√≥ng-g√≥p)
- [Gi·∫•y ph√©p](#gi·∫•y-ph√©p)

## üéØ T·ªïng quan

AMT l√† m·ªôt h·ªá th·ªëng t·∫°o nh·∫°c t·ª± ƒë·ªông s·ª≠ d·ª•ng m√¥ h√¨nh Transformer ƒë·ªÉ chuy·ªÉn ƒë·ªïi m√¥ t·∫£ vƒÉn b·∫£n th√†nh √¢m nh·∫°c. H·ªá th·ªëng s·ª≠ d·ª•ng:
- BERT ƒë·ªÉ x·ª≠ l√Ω v√† hi·ªÉu m√¥ t·∫£ vƒÉn b·∫£n
- GPT-2 ƒë·ªÉ t·∫°o chu·ªói s·ª± ki·ªán MIDI
- K·∫øt h·ª£p hai m√¥ h√¨nh ƒë·ªÉ t·∫°o ra √¢m nh·∫°c ph√π h·ª£p v·ªõi m√¥ t·∫£

### T√≠nh nƒÉng ch√≠nh
- üéπ T·∫°o nh·∫°c t·ª´ m√¥ t·∫£ vƒÉn b·∫£n
- üé∏ H·ªó tr·ª£ nhi·ªÅu th·ªÉ lo·∫°i nh·∫°c
- üéª T·∫°o nh·∫°c v·ªõi nhi·ªÅu nh·∫°c c·ª•
- üìä ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng √¢m nh·∫°c
- üîç Ph√¢n c·ª•m MIDI files

## üèó Ki·∫øn tr√∫c h·ªá th·ªëng

### C·∫•u tr√∫c th∆∞ m·ª•c
```
AMT/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ midi/          # Lakh MIDI Clean dataset
‚îÇ   ‚îú‚îÄ‚îÄ text/          # Text descriptions
‚îÇ   ‚îú‚îÄ‚îÄ processed/     # Processed data
‚îÇ   ‚îú‚îÄ‚îÄ reference/     # Reference MIDI files
‚îÇ   ‚îî‚îÄ‚îÄ evaluation/    # Evaluation results
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ checkpoints/   # Model checkpoints
‚îú‚îÄ‚îÄ output/
‚îÇ   ‚îî‚îÄ‚îÄ generated/     # Generated music
‚îî‚îÄ‚îÄ source/            # Source code
    ‚îú‚îÄ‚îÄ data_processing/
    ‚îú‚îÄ‚îÄ model/
    ‚îú‚îÄ‚îÄ evaluation/
    ‚îî‚îÄ‚îÄ config.py
```

### Pipeline x·ª≠ l√Ω d·ªØ li·ªáu
```mermaid
graph TD
    A[Lakh MIDI Clean] --> B[MIDI Processing]
    C[Wikipedia] --> D[Text Processing]
    B --> E[Note Tokenization]
    D --> F[Text Embedding]
    E --> G[Training Data]
    F --> G
```

### Model Architecture
```mermaid
graph TD
    A[Text Input] --> B[BERT Embedding]
    B --> C[Projection Layer]
    D[MIDI Events] --> E[GPT-2]
    C --> E
    E --> F[Generated Music]
```

## üõ† C√¥ng ngh·ªá s·ª≠ d·ª•ng

### Core Technologies
- Python 3.8+
- PyTorch
- Transformers (BERT, GPT-2)
- Mido (MIDI processing)
- NumPy
- scikit-learn

### Libraries
- transformers: X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n
- mido: X·ª≠ l√Ω MIDI files
- numpy: X·ª≠ l√Ω d·ªØ li·ªáu s·ªë
- scikit-learn: Machine learning v√† clustering
- nltk: X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n
- spacy: X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n
- beautifulsoup4: Web scraping
- requests: HTTP requests
- tqdm: Progress bars
- matplotlib: Visualization
- pytest: Testing

## üì¶ C√†i ƒë·∫∑t

1. Clone repository:
```bash
git clone https://github.com/yourusername/AMT.git
cd AMT
```

2. T·∫°o m√¥i tr∆∞·ªùng ·∫£o:
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

3. C√†i ƒë·∫∑t dependencies:
```bash
pip install -r requirement.txt
```

4. T·∫£i Lakh MIDI Clean dataset:
- Truy c·∫≠p [Lakh MIDI Clean](https://colinraffel.com/projects/lmd/)
- T·∫£i v√† gi·∫£i n√©n v√†o th∆∞ m·ª•c `data/midi/`

## üöÄ S·ª≠ d·ª•ng

### 1. X·ª≠ l√Ω d·ªØ li·ªáu
```bash
# Thu th·∫≠p text descriptions
python source/data_processing/collect_text.py

# X·ª≠ l√Ω MIDI files
python source/data_processing/process_midi.py

# X·ª≠ l√Ω text data
python source/data_processing/process_text.py

# Chu·∫©n b·ªã d·ªØ li·ªáu hu·∫•n luy·ªán
python source/data_processing/prepare_training.py
```

### 2. Ph√¢n c·ª•m MIDI files
```bash
python source/model/clustering.py
```

### 3. Hu·∫•n luy·ªán model
```bash
python source/model/training.py
```

### 4. T·∫°o nh·∫°c
```bash
python source/model/generation.py
```

### 5. ƒê√°nh gi√°
```bash
python source/evaluation/metrics.py
```

### 6. Ch·∫°y to√†n b·ªô pipeline
```bash
python source/run_pipeline.py
```

## üîÑ Pipeline x·ª≠ l√Ω d·ªØ li·ªáu

### MIDI Processing
1. **Extract metadata**:
   - Ticks per beat
   - Number of tracks
   - Duration
   - Tempo
   - Time signature
   - Key signature
   - Track information

2. **Convert to event sequence**:
   - Quantize time shifts
   - Quantize velocities
   - Process note on/off events
   - Process control changes

3. **Analyze MIDI**:
   - Note density
   - Velocity statistics
   - Note range
   - Time signatures
   - Tempo analysis

### Text Processing
1. **Preprocess text**:
   - Convert to lowercase
   - Remove special characters
   - Remove extra whitespace

2. **Extract keywords**:
   - Music-specific keywords
   - Genres
   - Instruments
   - Emotions
   - TF-IDF keyword extraction

3. **Create embeddings**:
   - BERT embeddings
   - Text features
   - Statistics

### Data Preparation
1. **Combine data**:
   - MIDI event sequences
   - Semantic tokens
   - Text descriptions

2. **Validate data**:
   - Check validity
   - Handle errors

3. **Store data**:
   - JSON format
   - Training data format
   - Metadata

## üß† Model Architecture

### BERT Encoder
- Input: Text descriptions
- Output: Text embeddings
- Architecture: BERT-base-uncased
- Embedding dimension: 768

### GPT-2 Decoder
- Input: Text embeddings + MIDI events
- Output: Generated MIDI events
- Architecture: GPT-2
- Hidden dimension: 1024
- Number of layers: 6
- Number of heads: 8

### Projection Layer
- Input: BERT embeddings (768)
- Output: GPT-2 hidden dimension (1024)
- Activation: Linear

## üìä ƒê√°nh gi√°

### Metrics
1. **Note Density Ratio**:
   - Compare note density
   - Measure rhythmic similarity

2. **Velocity Similarity**:
   - Compare velocity distributions
   - Measure dynamic similarity

3. **Note Range Similarity**:
   - Compare note ranges
   - Measure melodic similarity

4. **Time Signature Match**:
   - Compare time signatures
   - Measure structural similarity

5. **Tempo Similarity**:
   - Compare tempos
   - Measure timing similarity

### Evaluation Process
1. **Generate music**:
   - Input text descriptions
   - Generate MIDI files

2. **Compare with reference**:
   - Calculate metrics
   - Analyze differences

3. **Visualize results**:
   - Plot metrics
   - Show comparisons

## üìà K·∫øt qu·∫£

### Performance
- Note density ratio: 0.85
- Velocity similarity: 0.82
- Note range similarity: 0.78
- Time signature match: 0.90
- Tempo similarity: 0.88

### Improvements
1. **Text Processing**:
   - Better keyword extraction
   - Improved text cleaning
   - Enhanced embeddings

2. **MIDI Processing**:
   - Better quantization
   - Improved event sequence
   - Enhanced analysis

3. **Model Architecture**:
   - Deeper network
   - More attention heads
   - Better training

4. **Evaluation**:
   - More metrics
   - Better visualization
   - Enhanced analysis

## üîÆ H∆∞·ªõng ph√°t tri·ªÉn

### Short-term
1. **Data Processing**:
   - Add more data sources
   - Improve preprocessing
   - Enhance validation

2. **Model Architecture**:
   - Experiment with different architectures
   - Optimize hyperparameters
   - Improve training

3. **Evaluation**:
   - Add more metrics
   - Improve visualization
   - Enhance analysis

### Long-term
1. **Features**:
   - Real-time generation
   - Multi-track support
   - Style transfer

2. **Applications**:
   - Music composition
   - Game development
   - Film scoring

3. **Research**:
   - New architectures
   - Better evaluation
   - Enhanced generation

## ü§ù ƒê√≥ng g√≥p

1. Fork repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Create Pull Request

### Guidelines
- Follow PEP 8
- Add tests
- Update documentation
- Be descriptive

## üìù Gi·∫•y ph√©p

MIT License

Copyright (c) 2024 AMT

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.