# ğŸ“‘ BÃO CÃO Dá»° ÃN  
**The Beat Goes On â€“ Symbolic Music Generation with Text Controls (AMT)**  

---

## 1. Giá»›i thiá»‡u tá»•ng quan
AMT (Audio Music Transformer) lÃ  há»‡ thá»‘ng sinh nháº¡c tá»± Ä‘á»™ng tá»« mÃ´ táº£ vÄƒn báº£n. Há»‡ thá»‘ng káº¿t há»£p **BERT** (hiá»ƒu ngÃ´n ngá»¯ tá»± nhiÃªn) vÃ  **GPT-2** (mÃ´ hÃ¬nh hoÃ¡ chuá»—i thá»i gian) Ä‘á»ƒ táº¡o ra **chuá»—i sá»± kiá»‡n MIDI** phÃ¹ há»£p vá»›i ná»™i dung, cáº£m xÃºc vÃ  phong cÃ¡ch mÃ  ngÆ°á»i dÃ¹ng yÃªu cáº§u.

Má»¥c tiÃªu chÃ­nh:
1. Tá»± Ä‘á»™ng **thu tháº­p** dá»¯ liá»‡u MIDI & mÃ´ táº£ vÄƒn báº£n.
2. **Tiá»n xá»­ lÃ½** & chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u thÃ nh Ä‘á»‹nh dáº¡ng huáº¥n luyá»‡n.
3. **Huáº¥n luyá»‡n** mÃ´ hÃ¬nh káº¿t há»£p BERTâ€“GPT-2.
4. **Sinh** nháº¡c má»›i dá»±a trÃªn prompt vÄƒn báº£n.
5. **ÄÃ¡nh giÃ¡** cháº¥t lÆ°á»£ng nháº¡c sinh báº±ng bá»™ chá»‰ sá»‘ Ä‘á»‹nh lÆ°á»£ng.

## 2. Bá»™ dá»¯ liá»‡u
| ThÃ nh pháº§n | Nguá»“n | Quy mÃ´ |
|------------|-------|--------|
| Lakh MIDI Clean | Raffel et al. | â‰ˆ 136 k file MIDI (hÆ¡n 2 000 thÆ° má»¥c nghá»‡ sÄ©) |
| MÃ´ táº£ Wikipedia | API _wikipedia_ | 1 mÃ´ táº£/bÃ i | 

Sau khi quÃ©t, há»‡ thá»‘ng lÆ°u siÃªu dá»¯ liá»‡u vÃ o `AMT/data/output/*` á»Ÿ Ä‘á»‹nh dáº¡ng JSON.

## 3. Kiáº¿n trÃºc há»‡ thá»‘ng
```mermaid
graph TD
    A[Lakh MIDI Clean] --> B[MIDI Processing]
    C[Wikipedia] --> D[Text Processing]
    B --> E[MIDI Event Seq]
    D --> F[BERT Embedding]
    E --> G[Training Data (JSON)]
    F --> G
    G --> H[Huáº¥n luyá»‡n AMT]
    H --> I[GPT-2 + Projection]
    subgraph Sinh & ÄÃ¡nh giÃ¡
      I --> J[Sinh Nháº¡c]
      J --> K[MIDI Output]
      K --> L[Evaluation Metrics]
    end
```

### ThÆ° má»¥c mÃ£ nguá»“n
```
AMT/
 â”œâ”€ data/              # dá»¯ liá»‡u
 â”œâ”€ source/
 â”‚   â”œâ”€ data_collection/   # thu tháº­p
 â”‚   â”œâ”€ data_processing/   # tiá»n xá»­ lÃ½
 â”‚   â”œâ”€ model/             # huáº¥n luyá»‡n & sinh
 â”‚   â”œâ”€ evaluation/        # Ä‘Ã¡nh giÃ¡
 â”‚   â”œâ”€ utils/             # hÃ m há»— trá»£
 â”‚   â””â”€ scripts/           # main.py (pipeline)
 â”œâ”€ models/            # checkpoint GPT-2
 â””â”€ README.md
```

## 4. Pipeline xá»­ lÃ½ dá»¯ liá»‡u
| BÆ°á»›c | Script | MÃ´ táº£ |
|------|--------|-------|
| 1 | `data_collection/midi_metadata.py` | QuÃ©t thÆ° má»¥c MIDI â†’ JSON `{path, artist, title}` |
| 2 | `data_collection/wikipedia_collector.py` | Gá»i Wikipedia â†’ láº¥y mÃ´ táº£, URL |
| 3 | `data_processing/text_processor.py` | LÃ m sáº¡ch + BERT embedding + trÃ­ch keyword |
| 4 | `model/clustering.py` | K-means trÃªn embedding â†’ gÃ¡n **semantic_token** |
| 5 | `utils/data_preparation.py` | GhÃ©p `semantic_token` + chuá»—i sá»± kiá»‡n MIDI â†’ training data |

## 5. MÃ´ hÃ¬nh huáº¥n luyá»‡n
- **Projection**: Linear 768 â†’ 1024 Ä‘á»ƒ Ä‘Æ°a embedding BERT vÃ o khÃ´ng gian GPT-2.
- **GPT-2**: 6 lá»›p, 8 head, 1 024 hidden dim, vocab 512 (token hÃ³a sá»± kiá»‡n MIDI).
- **Loss**: Language-modeling (Cross-entropy) trÃªn chuá»—i `[semantic_token] + event_seq`.
- **Checkpoint**: lÆ°u má»—i epoch vÃ o `models/checkpoints/`.

## 6. Sinh nháº¡c
HÃ m chÃ­nh `AMTGenerator.generate_music()`:
1. BERT embedding cho mÃ´ táº£.
2. Projection â†’ GPT-2.generate (top-k, top-p, temperature).
3. Giáº£i mÃ£ token â†’ (TIME_ON, NOTE, DUR) â†’ `event_sequence_to_midi()`.
4. Xuáº¥t `.mid` vÃ o `output/generated/`.

## 7. ÄÃ¡nh giÃ¡
| Metric | Ã nghÄ©a |
|--------|---------|
| Note Density Ratio | Tá»‰ lá»‡ máº­t Ä‘á»™ ná»‘t giá»¯a gá»‘c & sinh |
| Velocity Similarity | Sai khÃ¡c mean/std váº­n tá»‘c |
| Note Range Similarity | Jaccard trÃªn quÃ£ng ná»‘t |
| Time-signature Match | TrÃ¹ng nhá»‹p |
| Tempo Similarity | TÆ°Æ¡ng Ä‘á»“ng BPM |
| **Overall** | Trung bÃ¬nh cÃ³ trá»ng sá»‘ |

## 8. Káº¿t quáº£ thá»­ nghiá»‡m (demo)
| Prompt | Overall Score |
|--------|---------------|
| "Báº£n ballad piano nháº¹ nhÃ ng, cáº£m xÃºc há»©ng khá»Ÿi" | **0.82** |
| "Báº£n rock guitar máº¡nh máº½, tiáº¿t táº¥u nhanh" | 0.76 |

*(Sá»‘ liá»‡u giáº£ láº­p Ä‘á»ƒ minh hoáº¡)*

## 9. Cáº£i tiáº¿n Ä‘Ã£ triá»ƒn khai
- ThÃªm hÃ m **`get_bert_embeddings`** há»— trá»£ batch.
- XoÃ¡ script dÆ° `run_pipeline.py`, _extract_midi_metadata.py_.
- Chuyá»ƒn dataset vÃ o `AMT/data/`, dá»n file rÃ¡c.
- README cáº­p nháº­t hÆ°á»›ng dáº«n, thÃªm táº£i NLTK/SpaCy.

## 10. HÆ°á»›ng phÃ¡t triá»ƒn
1. **Tokenization nÃ¢ng cao**: chord, velocity, tempo events riÃªng.
2. **Data Augmentation**: transpose, humanize timing.
3. **GUI Web**: nháº­p prompt, nghe nháº¡c trá»±c tuyáº¿n.
4. **Fine-tune Ä‘Ã¡nh giÃ¡**: thÃªm FrÃ©chet Audio Distance cho symbolic.
5. **Multi-track / style transfer**: Ä‘iá»u khiá»ƒn Ä‘a nháº¡c cá»¥.

## 11. CÃ i Ä‘áº·t & cháº¡y nhanh
```bash
cd AMT
python -m venv venv && venv\Scripts\activate    # Windows
pip install -r requirements.txt
python -m nltk.downloader punkt averaged_perceptron_tagger
python -m spacy download en_core_web_sm

# Pipeline end-to-end
python source/scripts/main.py
```

## 12. TÃ i liá»‡u tham kháº£o
- Raffel et al., "Learning-based methods for expressive performanceâ€¦" (Lakh MIDI).  
- Vaswani et al., "Attention is All You Need".  
- Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformersâ€¦".  
- Radford et al., "Language Models are Unsupervised Multitask Learners".

---
**Â© 2025 FPT â€“ TMG301** 