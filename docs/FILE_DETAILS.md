# üìö Chi Ti·∫øt N·ªôi Dung T·ª´ng File ‚Äì D·ª± √Ån AMT

> T√†i li·ªáu n√†y m√¥ t·∫£ **ch·ª©c nƒÉng chi ti·∫øt** c·ªßa t·ª´ng t·ªáp quan tr·ªçng trong d·ª± √°n `AMT`. C√°c file ƒë∆∞·ª£c s·∫Øp x·∫øp theo th∆∞ m·ª•c ƒë·ªÉ ti·ªán tra c·ª©u. Nh·ªØng t·ªáp kh√¥ng ·∫£nh h∆∞·ªüng tr·ª±c ti·∫øp (cache, \_\_pycache\_\_, file d·ªØ li·ªáu) ƒë∆∞·ª£c b·ªè qua.

---

## 1. G·ªëc d·ª± √°n
| File/Th∆∞ m·ª•c | M√¥ t·∫£ |
|--------------|-------|
| `requirements.txt` | Li·ªát k√™ th∆∞ vi·ªán Python c·∫ßn c√†i ƒë·∫∑t. |
| `README.md` | H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t, ch·∫°y, ki·∫øn tr√∫c t·ªïng th·ªÉ. |
| `PROJECT_REPORT.md` | B√°o c√°o t·ªïng quan d·ª± √°n (m·ª•c ti√™u, m√¥ h√¨nh, k·∫øt qu·∫£). |
| `FILE_OVERVIEW_AND_DATA_FLOW.md` | S∆° ƒë·ªì c√¢y th∆∞ m·ª•c & lu·ªìng d·ªØ li·ªáu. |
| `FILE_DETAILS.md` | (t·ªáp hi·ªán t·∫°i) b·∫£ng ch√∫ gi·∫£i chi ti·∫øt t·ª´ng t·ªáp. |
| `paper/` | Ch·ª©a c√°c b√†i b√°o tham kh·∫£o. |

---

## 2. Th∆∞ m·ª•c `AMT/data`
| Th∆∞ m·ª•c con | M·ª•c ƒë√≠ch |
|--------------|----------|
| `midi/` | Lakh MIDI Clean (input). |
| `text/` | Text m√¥ t·∫£ th√¥ (n·∫øu thu th·∫≠p th·ªß c√¥ng). |
| `processed/` | D·ªØ li·ªáu ƒë√£ token ho√° / vector ho√°. |
| `output/` | C√°c JSON trung gian (`*_metadata.json`, `*_embeddings.json`, ...). |
| `reference/` | MIDI m·∫´u ƒë·ªÉ ƒë√°nh gi√°. |
| `evaluation/` | B√°o c√°o metric chi ti·∫øt sau khi sinh nh·∫°c. |

---

## 3. Th∆∞ m·ª•c `AMT/source`

### 3.1 `config.py`
- **Lo·∫°i:** Module c·∫•u h√¨nh.
- **N·ªôi dung ch√≠nh:** H·∫±ng s·ªë v·ªÅ d·ªØ li·ªáu, model, training, generation v√† evaluation; h√†m `get_config()` t·ªïng h·ª£p t·∫•t c·∫£.

### 3.2 `__init__.py`
- Khai b√°o namespace `AMT.source` export c√°c sub-package `data_processing`, `model`, `evaluation`, `config`.

---

### 3.3 `data_collection/`
| File | M√¥ t·∫£ chi ti·∫øt |
|------|----------------|
| `midi_metadata.py` | ‚Ä¢ H√†m `list_midi_files_and_metadata(base_dir)` duy·ªát ƒë·ªá quy th∆∞ m·ª•c, tr√≠ch `artist` theo t√™n th∆∞ m·ª•c, `title` theo t√™n file.  <br>‚Ä¢ H√†m `save_metadata(...)` ghi JSON. <br>‚Ä¢ Kh·ªëi `main()` (argparse) ƒë·ªÉ ch·∫°y CLI. |
| `wikipedia_collector.py` | ‚Ä¢ H√†m `get_wikipedia_summary(artist,title)` t√¨m page qua `wikipedia` pkg. <br>‚Ä¢ H√†m `pair_midi_with_wikipedia(metadata_file, output_file)` ƒë·ªçc JSON metadata, g·ªçi API, sleep gi·ªØa request, ghi `automated_paired_data.json`. <br>‚Ä¢ S·ª≠ d·ª•ng regex l√†m s·∫°ch, x·ª≠ l√Ω PageError, DisambiguationError. |
| `__init__.py` | G√°n alias, kh√¥ng ch·ª©a logic. |

---

### 3.4 `data_processing/`
| File | M√¥ t·∫£ chi ti·∫øt |
|------|----------------|
| `midi_processor.py` | **Tr√°i tim symbolic processing**. <br>‚Ä¢ H·∫±ng s·ªë TIME_RESOLUTION, MAX_TIME_SHIFT,... <br>‚Ä¢ H√†m `get_midi_metadata` (tr√≠ch meta track, tempo, time sig). <br>‚Ä¢ H√†m `midi_to_event_sequence` & `event_sequence_to_midi`. <br>‚Ä¢ H√†m `analyze_midi_file` (t√≠nh density, range, velocity, tempo). |
| `text_processor.py` | ‚Ä¢ H√†m `clean_text`, `extract_music_keywords`, `extract_keywords` (TF-IDF). <br>‚Ä¢ H√†m `get_text_features` tr·∫£ dict th·ªëng k√™ + keyword. <br>‚Ä¢ H√†m `get_bert_embedding` (tokenizer & model BERT-base) & `get_bert_embeddings` (batch). <br>‚Ä¢ H√†m `scrape_wikipedia` (d·ª± ph√≤ng). <br>‚Ä¢ H√†m `process_text_descriptions` th·ªëng k√™ to√†n t·∫≠p. <br>‚Ä¢ H√†m `create_training_examples`. |
| `collect_text.py` | Placeholder thu text (√≠t logic). |
| `process_midi.py` | G·ªçi `midi_processor` tr√™n to√†n b·ªô th∆∞ m·ª•c r·ªìi xu·∫•t th·ªëng k√™ (demo). |
| `process_text.py` | G·ªçi `text_processor.process_text_descriptions`. |
| `prepare_training.py` | Wrapper g·ªçi `utils/data_preparation`. |
| `__init__.py` | Xu·∫•t h·∫±ng/func ti·ªán d·ª•ng. |

---

### 3.5 `model/`
| File | Chi ti·∫øt |
|------|---------|
| `training.py` | ‚Ä¢ Class `AMTDataset` ƒë·ªçc `amt_training_data.json`. <br>‚Ä¢ Class `AMTModel`: Linear projection 768‚Üí1024 + GPT-2 (6 layers). <br>‚Ä¢ H√†m `train_model` ch·∫°y DataLoader, Adam, checkpoint. <br>‚Ä¢ `__main__` -> parse path m·∫∑c ƒë·ªãnh & hu·∫•n luy·ªán. |
| `generation.py` | ‚Ä¢ Class `MusicGenerator` d√πng tokenizer HF + GPT-2 fine-tuned. <br>‚Ä¢ Class `AMTGenerator`: load checkpoint, sinh sequence t·ª´ text embedding, convert event‚ÜíMIDI. <br>‚Ä¢ H√†m `load_generator`, `save_generated_sequences`. |
| `clustering.py` | ‚Ä¢ H√†m `determine_optimal_k`, `cluster_embeddings`. <br>‚Ä¢ Class `MIDIClusterer` (ph√¢n c·ª•m theo ƒë·∫∑c tr∆∞ng √¢m nh·∫°c). <br>‚Ä¢ H√†m `cluster_midi_files` convenience. |
| `__init__.py` | Exports. |

---

### 3.6 `evaluation/`
| File | N·ªôi dung |
|------|----------|
| `metrics.py` | ƒê·ªãnh nghƒ©a 5 metric (density, velocity, range, time-sig, tempo) + `evaluate_generated_music` v√† `evaluate_batch`. |
| `__init__.py` | Import metric list. |

---

### 3.7 `utils/`
| File | N·ªôi dung |
|------|----------|
| `data_preparation.py` | ƒê·ªçc `clustered_text_data.json`, gh√©p SEMANTIC_TOKEN_i + chu·ªói event, l∆∞u `amt_training_data.json`. <br>‚Ä¢ Log ti·∫øn ƒë·ªô, x·ª≠ l√Ω l·ªói file m·∫•t. |
| `environment.py` | In version `torch`, `transformers`, `mido`, ... ƒë·ªÉ debug m√¥i tr∆∞·ªùng. |
| `__init__.py` | Shortcut import. |

---

### 3.8 `scripts/`
| File | N·ªôi dung |
|------|----------|
| `main.py` | Pipeline "one-click": verify env ‚Üí metadata ‚Üí wiki ‚Üí embedding ‚Üí clustering ‚Üí prepare training. |
| `__init__.py` | Dummy. |

---

## 4. Th∆∞ m·ª•c `models/`
- Tr·ªëng ban ƒë·∫ßu, s·∫Ω ch·ª©a `checkpoints/checkpoint_epoch_*.pt` do `training.py` sinh.

## 5. Th∆∞ m·ª•c `paper/`
- T√†i li·ªáu tham kh·∫£o PDF ("The Beat Goes On-...", "Anticipatory Music Transformer", ...).

---

## 6. Li√™n h·ªá gi·ªØa file
- **data_collection** sinh JSON ƒë·∫ßu v√†o cho **data_processing/text_processor**.  
- **text_processor** + **clustering** cung c·∫•p semantic_token cho **utils/data_preparation**.  
- **training.py** ti√™u th·ª• output ƒë√≥, sinh checkpoint cho **generation.py**.  
- **generated midi** + **reference midi** ƒëi v√†o **evaluation/metrics.py**.

---
**T√†i li·ªáu ho√†n t·∫•t ‚Äì m·ªçi file quan tr·ªçng ƒë·ªÅu ƒë∆∞·ª£c m√¥ t·∫£.** 